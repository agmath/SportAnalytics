---
title: "Football Analytics"
author: "Adam Gilbert"
format: html
theme: flatly
date: today
toc: true
---

## Introduction

This notebook contains sections corresponding to the textbook *Football Analytics with Python & R*, by Eric A. Eager and Richard A. Erickson. I include a subsection in this notebook for each chapter of the text, and include solutions to exercises as well as some explorations of different questions I thought may be interesting to explore.

## Chapter 1: Football Analytics

This introductory chapter provides the reader an introduction to R and Python as well as to the `{nflfastR}` package in R (and the `nfl_data_py` Python module). I'll be working through the textbook in R, since that is my preferred language.

```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(kableExtra)
library(nflfastR)
library(patchwork)
library(tidymodels)
```

We can load *play-by-play* data using the `load_pbp()` function from this package. I'll load the data from the 2021 season, as shown in the textbook.

```{r}
pbp_21 <- load_pbp(2021)

pbp_21 %>%
  head(n = 2) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

This collection of play-by-play data from the 2021 season includes `r pbp_21 %>% nrow()` observations on `r pbp_21 %>% ncol()` variables. The text guides us through a simple example of ranking quarterbacks by their level of *agressivity*, as defined by average pass depth (`air_yards`). In order to perform this analysis, we'll filter to include only pass plays with recorded `air_yards` values. After computing the summary statistics, we filter out unknown passers and passers who attempted very few passes.

```{r}
pbp_21 %>%
  filter((play_type == "pass") & (!is.na(air_yards))) %>%
  group_by(passer_id, passer) %>%
  summarize(num_passes = n(), avg_depth_of_pass = mean(air_yards),
            .groups = "drop") %>%
  filter((num_passes >= 100) & (!is.na(passer))) %>%
  arrange(-avg_depth_of_pass) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

The below plots show pass depth distributons for each of the top fifteen quarterbacks listed above.

```{r}
deepest_passers <- pbp_21 %>%
  filter((play_type == "pass") & (!is.na(air_yards))) %>%
  group_by(passer_id, passer) %>%
  summarize(num_passes = n(), avg_depth_of_pass = mean(air_yards),
            .groups = "drop") %>%
  filter((num_passes >= 100) & (!is.na(passer))) %>%
  arrange(-avg_depth_of_pass) %>%
  slice_max(avg_depth_of_pass, n = 15) %>%
  pull(passer)

pbp_21 %>%
  filter((play_type == "pass") & (!is.na(air_yards)) & (passer %in% deepest_passers)) %>%
  mutate(passer = factor(passer, levels = deepest_passers)) %>%
  ggplot() + 
  geom_density(aes(x = air_yards, fill = passer), show.legend = FALSE) + 
  geom_boxplot(aes(x = air_yards, y = -0.02, fill = passer), width = 0.01, show.legend = FALSE) + 
  facet_wrap(~passer, nrow = 3) + 
  labs(title = "Pass Depth Distributions for 2021's Deepest Average Passers",
       x = "Air Yards",
       y = "")
```

It is interesting how similar these distributions look. Drew Lock had the highest average `air_depth` but he also had the fewest total passes among this group. This means that those very few deep-ball outliers had greater influence on his average pass depth than the other quarterbacks who played more snaps.

## Chapter 2: EDA through Stable Versus Unstable QB Stats

The authors include an interesting discussion on how players should be evaluated. Some statistical measures are relatively stable for players year-over-year, while others include more variability. This introduces the possibility for strategic trading on high-variability measures -- we can *sell-high* and *buy-low* on players based on such performance measures if other teams are placing undue weight on these high-variance and unstable stats. For example, yards gained by a running back are not generally stable and neither are yards gained as a result of deep throws from a quarterback. Yards gained by short passes, however, are generally stable year-over-year. Let's analyse some of these ideas. 

In the text, the authors use EDA to explore the hypothesis: *Throwing deep passes is more valuable than short passes, but it is difficult to say whether a quarterback is "good" at deep passes*. Here, the variability comes in with the latter half of the hypothesis -- determining whether a quarterback excels in deep passing is difficult because of the high variability in deep passing statistics year-over-year.

Since we are discussing year-over-year comparisons, we'll need to load several seasons-worth of data. We'll do that now.

```{r}
pbp_16_21 <- load_pbp(2016:2021)
```

We've got a lot more data to deal with now. Certainly, the number of features (variables) has stayed the same, but now we have `r pbp_16_21 %>% nrow()` observations across the six seasons. The authors justify looking at 2016 to 2021 because the beginning of the 2016 season was the last time a major rule change was implemented. A touchback on a kickoff resulted in starting from the 25 yard line rather than the 20 yard line. This rule change resulted in a change in kickoff strategy across the league, so analysing pre- and post-2016 data separately is justifiable.

Let's take a look at year-over-year short and long pass results. We'll use the `air_yards` variable to separate pass attempts into *long* (at least 20 yards) and *short* (less than 20 yards), and start with some simple numeric summaries, looking at *expected points added` (`epa`) by long/short pass plays.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass",
         !(is.na(air_yards))) %>%
  mutate(passing_yards = ifelse(is.na(passing_yards), 0, passing_yards),
         pass_type = ifelse(air_yards >= 20, "long", "short")) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  group_by(pass_type) %>%
  summarize(
    min_epa = min(epa, na.rm = TRUE),
    q1_epa = quantile(epa, 0.25, na.rm = TRUE),
    med_epa = median(epa, na.rm = TRUE),
    mean_epa = mean(epa, na.rm = TRUE),
    q3_epa = quantile(epa, 0.75, na.rm = TRUE),
    max_epa = max(epa, na.rm = TRUE),
    iqr_epa = IQR(epa, na.rm = TRUE),
    sd_epa = sd(epa, na.rm = TRUE),
    missing_count = sum(is.na(epa)),
    .groups = "drop"
  ) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

We can see that expected points added has greater variation on long pass plays than it does on short pass plays.

We'll build a plot to compare passing stats between pairs of consecutive years, investigating stability of `passing_yards`. Let's start by simply drawing the distributions of passing yards resulting from long and short pass plays.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
         passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_histogram(aes(x = passing_yards, y = ..density.., fill = pass_type), 
                 binwidth = 1, color = "black", show.legend = FALSE) +
  #geom_density(aes(x = passing_yards, fill = pass_type),
  #             alpha = 0.4, show.legend = FALSE) + 
  geom_boxplot(aes(x = passing_yards, y = -0.02, fill = pass_type), 
               width = 0.01, show.legend = FALSE) + 
  labs(
    title = "Distribution of Passing Yards by Pass Type",
    x = "Passing Yards",
    y = ""
  ) + 
  facet_wrap(~pass_type)
```

We can see that lots of pass plays in general do not result in catches. Long passes, however, are much less likely to result in a completion. Interestingly, the distribution of passing yards on short passes, looks to be normally distributed when dropped balls are omitted.

Now that we have these insights, let's take a look at the distributions of expected points added on these plays as well.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
         passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_histogram(aes(x = epa, y = ..density.., fill = pass_type), 
                 bins = 50, color = "black", show.legend = FALSE) +
  geom_density(aes(x = epa, fill = pass_type),
               alpha = 0.4, show.legend = FALSE) + 
  geom_boxplot(aes(x = epa, y = -0.02, fill = pass_type), 
               width = 0.01, show.legend = FALSE) + 
  labs(
    title = "Distribution of Expected Points Added by Pass Type",
    x = "Passing Yards",
    y = ""
  ) + 
  facet_wrap(~pass_type)
```

From the plots above, we again see that the long passes show greater variability in terms of expected points added. On average, the `epa` values here are lower than for short passes, however we do see that when long passes result in receptions [assumedly], the `epa` values are much greater.

Now let's see whether average passing yards on short- and long- passing attemps are stable metrics year over year. We'll remove passers that threw very few attempts in a season, since these often include non-QB players throwing passes on trick plays that may end up in very large gains.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
         passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            avg_pass_yards = mean(passing_yards),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
             passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                avg_pass_yards = mean(passing_yards),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(avg_pass_yards_curr = avg_pass_yards.x,
         avg_pass_yards_next = avg_pass_yards.y) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_point(aes(x = avg_pass_yards_curr, y = avg_pass_yards_next)) + 
  geom_smooth(aes(x = avg_pass_yards_curr, y = avg_pass_yards_next),
              method = "lm") + 
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") + 
  facet_wrap(~pass_type) + 
  labs(
    title = "Year-to-Year Stability of Passing Yards",
    x = "Current Year Passing Yards",
    y = "Next Year Passing Yards"
  )
```

We can see that there is a positive correlation between year over year passing yards. That correlation looks to be stronger on short passes. Let's see this numerically below.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
         passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            avg_pass_yards = mean(passing_yards),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
             passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                avg_pass_yards = mean(passing_yards),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(avg_pass_yards_curr = avg_pass_yards.x,
         avg_pass_yards_next = avg_pass_yards.y) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  group_by(pass_type) %>%
  summarize(y2y_avg_pass_yards_correlation = cor(avg_pass_yards_curr, avg_pass_yards_next)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

### Homework Exercises

The following are the exercises at the end of this chapter.

1. Create histograms using `epa` (Expected Points Added) per pass attempt.

> I ended up doing this earlier in the *notes* section.

2. Create boxplots using `epa` per pass attempt.

> I also ended up doing this earlier in the *notes* section.

3. Perform the stability analysis for average `epa` per pass attempt. Interpret the results. Do any players have similar yards per attempt year over year, but quite different EPA values? Where could this come from?

> In the plot below, I'll compare average EPA values for consecutive years. I'll add player names to the plot in any cases where the average EPA for consecutive years differed by a full point or more.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            avg_epa = mean(epa, na.rm = TRUE),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                avg_epa = mean(epa, na.rm = TRUE),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(avg_epa_curr = avg_epa.x,
         avg_epa_next = avg_epa.y) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_point(aes(x = avg_epa_curr, y = avg_epa_next)) + 
  geom_smooth(aes(x = avg_epa_curr, y = avg_epa_next),
              method = "lm") + 
  geom_text(aes(x = avg_epa_curr, y = avg_epa_next, label = ifelse(abs(avg_epa_curr - avg_epa_next) > 1, passer, ""))) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") + 
  facet_wrap(~pass_type) + 
  labs(
    title = "Year-to-Year Stability of Expected Points Added",
    x = "Current Year Average EPA",
    y = "Next Year Average EPA"
  )
```

> Similar to what we did with the year-over-year passing yards, we'll compute the correlation between consecutive year average EPA per pass attempt for long and short passes.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            avg_epa = mean(epa, na.rm = TRUE),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                avg_epa = mean(epa, na.rm = TRUE),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(avg_epa_curr = avg_epa.x,
         avg_epa_next = avg_epa.y) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  group_by(pass_type) %>%
  summarize(y2y_avg_epa_correlation = cor(avg_epa_curr, avg_epa_next)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

> The correlation here is still stronger for *short* passes than *long* pass attempts. To answer the remaining question about players with stable YPA values, but unstable EPA values, I'll compute the change in YPA over consecutive years and do the same with the change in EPA per attempt over consecutive years. Then I'll plot the results and identify players far from the 45-degree diagonal.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            ypa = mean(passing_yards, na.rm = TRUE),
            avg_epa = mean(epa, na.rm = TRUE),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                ypa = mean(passing_yards, na.rm = TRUE),
                avg_epa = mean(epa, na.rm = TRUE),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(ypa_curr = ypa.x,
         ypa_next = ypa.y,
         avg_epa_curr = avg_epa.x,
         avg_epa_next = avg_epa.y) %>%
  mutate(ypa_delta = ypa_next - ypa_curr,
         avg_epa_delta = avg_epa_next - avg_epa_curr) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_point(aes(x = ypa_delta, y = avg_epa_delta)) + 
  geom_text(aes(x = ypa_delta, y = avg_epa_delta, label = ifelse(abs(avg_epa_delta) > 1, passer, ""))) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") + 
  facet_wrap(~pass_type) + 
  labs(
    title = "Change in YPA with Change in Average EPA",
    x = "Change in YPA",
    y = "Change in Average EPA"
  )
```

> WIth the exception of Tua, these look like players who have switched teams fairly often throughout their careers. A switch in team means a switch in coaching staff and strategy. We could plot the year in addition to the player name and then check on this hypothesis if we wanted.

4. Find a cutoff that equally splits the data between *long* and *short* pass attempts and then re-run the analysis. 

> I'm not going to repeat the analysis right now, but we can find the median pass attempt length to determine a more equitable cutoff than 20 yards for `air_yards`. That cutoff would be about `r round(median(pbp_16_21$air_yards, na.rm = TRUE), 1)`.

## Chapter 3: Linear Regression and Rushing Yards Over Expected

We'll continue with the 2016 - 2021 play-by-play data in this chapter. Here, however, we'll focus on rushing yards. The main ideas presented are quite interesting -- basically, not all rushes are created equally. If a rusher gains 6 yards, when 8 are needed, then they did not achieve their objective. However, if a rusher gains 2 yards on a 3rd and 1, then that rusher has done their job and the play was successful. We need ways to assess the quality of a play, while controlling for the current game conditions -- for example, down and yards to go.

Let's start by looking at the relationship between yards to gain (yards to a first down or touchdown) and the rushing yards gained on a running play.

```{r}
pbp_16_21 %>%
  count(play_type)

p1 <- pbp_16_21 %>%
  filter(play_type == "run") %>%
  ggplot() + 
  geom_point(aes(x = ydstogo, y = rushing_yards), alpha = 0.25) + 
  geom_smooth(aes(x = ydstogo, y = rushing_yards), method = "lm") + 
  labs(title = "Rushing Yards Gained versus Yards to Go",
       x = "Yards to Go",
       y = "Rushing Yards Gained")

p2 <- pbp_16_21 %>%
  filter(play_type == "run") %>%
  ggplot() + 
  geom_boxplot(aes(x = ydstogo, y = rushing_yards, group = ydstogo)) + 
  geom_smooth(aes(x = ydstogo, y = rushing_yards), method = "lm") + 
  labs(title = "Rushing Yards Gained versus Yards to Go",
       x = "Yards to Go",
       y = "Rushing Yards Gained")

p1 + p2
```

This is really noisy data. Let's see if we can get some better insight by averaging the number of rushing yards gained at each yards-to-go threshold.

```{r}
pbp_16_21 %>%
  filter(play_type == "run") %>%
  group_by(ydstogo) %>%
  summarize(avg_rush_gain = mean(rushing_yards)) %>%
  ggplot() + 
  geom_point(aes(x = ydstogo, y = avg_rush_gain)) + 
  geom_smooth(aes(x = ydstogo, y = avg_rush_gain), method = "lm") + 
  labs(title = "Average Rush Yards Gained by Yards to Go",
       x = "Yards to Go",
       y = "Average Rushing Yards Gained")
```

Let's build and analyse a simple linear regression model to predict rushing yards gained, by the current yards to go.

```{r}
lin_reg_spec <- linear_reg() %>%
  set_engine("lm")

lin_reg_rec <- recipe(rushing_yards ~ ydstogo, data = pbp_16_21)

lin_reg_wf <- workflow() %>%
  add_model(lin_reg_spec) %>%
  add_recipe(lin_reg_rec)

lin_reg_fit <- lin_reg_wf %>%
  fit(pbp_16_21)
```

Now that we have a fitted model, we can see the global model utility metrics below.

```{r}
lin_reg_fit %>%
  glance() %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Similarly, we can see the statistical measures on the individual model terms below as well.

```{r}
lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

We can now use our model to obtain residuals and explore Rushing Yards Over Expected (RYOE).

```{r}
lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run") %>%
      select(rusher, ydstogo, rushing_yards)
  ) %>%
  mutate(RYOE = .pred - rushing_yards) %>%
  ggplot() + 
  geom_point(aes(x = ydstogo, y = RYOE)) + 
  geom_text(aes(x = ydstogo, y = RYOE, label = ifelse(RYOE > quantile(RYOE, 0.9999, na.rm = TRUE), rusher, ""))) + 
  ylim(c(0, 40)) +
  labs(title = "Most Successful Rushes",
       x = "Yards to Gain",
       y = "Rushing Yards Over Expected")
```

Notice that those rushes which are longer than expected seemed to occur on yardages typically thought of as throwing situations. These were relatively long-yardage scenarios.

Let's dive deeper into RYOE, and understand which players had the highest average RYOE in each season. We'll then determine the stability of the RYOE metric from one year to the next, similarly to the way we determined the stability of passing yards on short- and long- passes in the previous chapter.

```{r}
lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run", !is.na(rusher)) %>%
      select(rusher_id, rusher, season, ydstogo, rushing_yards) %>%
      mutate(rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)) 
    ) %>%
  rename(expected_yards = .pred) %>%
  mutate(ryoe = rushing_yards - expected_yards) %>%
  group_by(rusher_id, rusher, season) %>%
  summarize(
    runs = n(),
    avg_ryoe = mean(ryoe),
    avg_rush_yards = mean(rushing_yards),
    total_ryoe = sum(ryoe),
    total_rush_yards = sum(rushing_yards),
    .groups = "drop"
  ) %>%
  filter(runs >= 50) %>%
  arrange(-avg_ryoe) %>%
  head(n = 20) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

As in the textbook, we see several Quarterbacks at the top of the list. In particular, Lamar Jackson had several great seasons, as measured by RYOE. This is part of what led to him being given an enormous contract in 2023.

If we arrange rushers by `total_ryoe` rather than `avg_ryoe`, we see the following results.

```{r}
lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run", !is.na(rusher)) %>%
      select(rusher_id, rusher, season, ydstogo, rushing_yards) %>%
      mutate(rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)) 
    ) %>%
  rename(expected_yards = .pred) %>%
  mutate(ryoe = rushing_yards - expected_yards) %>%
  group_by(rusher_id, rusher, season) %>%
  summarize(
    runs = n(),
    avg_ryoe = mean(ryoe),
    avg_rush_yards = mean(rushing_yards),
    total_ryoe = sum(ryoe),
    total_rush_yards = sum(rushing_yards),
    .groups = "drop"
  ) %>%
  filter(runs >= 50) %>%
  arrange(-total_ryoe) %>%
  head(n = 20) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Again, like the text, we see Jonathan Taylor and Derrick Henry topping this list.

Now let's see whether `avg_ryoe` and `total_ryoe` are stable metrics from one year to the next.

```{r}
rush_stats_16_21 <- lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run", !is.na(rusher)) %>%
      select(rusher_id, rusher, season, ydstogo, rushing_yards) %>%
      mutate(rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)) 
    ) %>%
  rename(expected_yards = .pred) %>%
  mutate(ryoe = rushing_yards - expected_yards) %>%
  group_by(rusher_id, rusher, season) %>%
  summarize(
    runs = n(),
    avg_ryoe = mean(ryoe),
    avg_rush_yards = mean(rushing_yards),
    total_ryoe = sum(ryoe),
    total_rush_yards = sum(rushing_yards),
    .groups = "drop"
  ) %>%
  filter(runs > 50) %>%
  mutate(next_season = season + 1) %>%
  select(rusher_id, rusher, season, next_season, runs, avg_ryoe, 
         avg_rush_yards, total_ryoe, total_rush_yards)

rush_stats_16_21 %>%
  select(-season) %>%
  inner_join(
    rush_stats_16_21 %>%
      select(-next_season),
    by = c("rusher_id" = "rusher_id", "rusher" = "rusher", "next_season" = "season")
    ) %>%
    summarize(
      rushes = cor(runs.x, runs.y),
      avg_ryoe = cor(avg_ryoe.x, avg_ryoe.y),
      avg_rush_yds = cor(avg_rush_yards.x, avg_rush_yards.y),
      total_ryoe = cor(total_ryoe.x, total_ryoe.y),
      total_rush_yds = cor(total_rush_yards.x, total_rush_yards.y)
    ) %>%
  pivot_longer(cols = everything(), names_to = "metric", values_to = "y2y_correlation") %>%
  arrange(-y2y_correlation) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Notice that `total_rush_yds`, and `total_ryoe` are difficult to interpret because volume is a masked variable in both of these measures. These metrics actually measure two things -- the frequency of run attempts and the length of each run. We aren't reproducing the exact numbers from the textbook here. I'm wondering if that is due to stat updates, or if my code is not identical to the code found in the text.

### Exercises

1. What happens if you repeat the correlation analysis, but use 100 rushes per season as the threshold rather than 50? Are the takeaways regarding stability the same?

```{r}
rush_stats_16_21 <- lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run", !is.na(rusher)) %>%
      select(rusher_id, rusher, season, ydstogo, rushing_yards) %>%
      mutate(rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)) 
    ) %>%
  rename(expected_yards = .pred) %>%
  mutate(ryoe = rushing_yards - expected_yards) %>%
  group_by(rusher_id, rusher, season) %>%
  summarize(
    runs = n(),
    avg_ryoe = mean(ryoe),
    avg_rush_yards = mean(rushing_yards),
    total_ryoe = sum(ryoe),
    total_rush_yards = sum(rushing_yards),
    .groups = "drop"
  ) %>%
  filter(runs > 100) %>%
  mutate(next_season = season + 1) %>%
  select(rusher_id, rusher, season, next_season, runs, avg_ryoe, 
         avg_rush_yards, total_ryoe, total_rush_yards)

rush_stats_16_21 %>%
  select(-season) %>%
  inner_join(
    rush_stats_16_21 %>%
      select(-next_season),
    by = c("rusher_id" = "rusher_id", "rusher" = "rusher", "next_season" = "season")
    ) %>%
    summarize(
      rushes = cor(runs.x, runs.y),
      avg_ryoe = cor(avg_ryoe.x, avg_ryoe.y),
      avg_rush_yds = cor(avg_rush_yards.x, avg_rush_yards.y),
      total_ryoe = cor(total_ryoe.x, total_ryoe.y),
      total_rush_yds = cor(total_rush_yards.x, total_rush_yards.y)
    ) %>%
  pivot_longer(cols = everything(), names_to = "metric", values_to = "y2y_correlation") %>%
  arrange(-y2y_correlation) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

> We do see that `avg_ryoe` is still a more stable measure than `avg_rush_yds` from one year to the next. The different in correlations is similar -- about $0.016$ versus $0.013$ -- although, this is about a 23% increase in the difference. Interestingly, we see that the correlation between total runs and total rush yards from year to year has dropped significantly. This indicates that dominant rushers (rushers getting lots of carries) don't generally hold over from one year to the next. This could be due to wear and tear on the position.

2. Assume that all of Mike Alstott's carries were on 3rd and 1 situations, while all Warrick Dunn's carries were on 1st and 10s. Is situation alone enough to explain the difference between the yards per carry for these two players (3.7 yards per carry versus 4.0 yards per carry)?

```{r}
lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy() %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

> Notice that the coefficient on yards to go in the regression model is about 0.113. If we multiply this by 9 (the difference in the assumed yards to go measures), we expect a difference of about a full yard (in terms of expected rushing yards). This would be more than enough to explain the difference in yards per carry for these two backs.

3. What happens if you repeat the analyses in the chapter with yards to the endzone (`yard_line_100`) rather than yards to gain?

> I'm omitting this for now, but it should be simple to do.

4. Conduct an analysis analogous to the one in this chapter, but for receivers and the passing game.

> Again, I'm omitting for now, but it should be easy to conduct.

## Chapter 4: Multiple Linear Regression and Rushing Yards Over Expected, Revisited

In Chapter 3, we controlled for just a single variable. However, the result of a rushing play is almost surely to depend on more than simply the *yards to gain*. For example, A 2nd and 1 is a very different play than a 4th and 1. In the former, the defense may expect a long passing play and needs to defend against that, while in the latter, it is much more likely that the offense will simply try to reach the line to gain and so defenses in these situations are defending primarily against short plays.

In this chapter, we'll build our regression model to control for more gameplay scenarios.

```{r}
pbp_16_22 <- load_pbp(2016:2022)

pbp_run <- pbp_16_22 %>%
  filter((play_type == "run") & (!is.na(rusher_id)) & (!is.na(down)) & (!is.na(run_location))) %>%
  mutate(
    rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)
  )

pbp_run %>%
  ggplot() + 
  geom_density(aes(x = rushing_yards, fill = run_location)) +
  facet_grid(down ~ run_location) + 
  theme_bw() +
  theme(legend.position = "none")
```

```{r}
p_all_runs <- pbp_run %>%
  ggplot() + 
  geom_boxplot(aes(x = down, y = rushing_yards, group = down))

p_ten_to_run <- pbp_run %>%
  filter(ydstogo == 10) %>%
  ggplot() + 
  geom_boxplot(aes(x = down, y = rushing_yards, group = down))

p_all_runs + p_ten_to_run
```

Let's plot rushing yards gained against the starting yard line for the play.

```{r}
pbp_run %>%
  ggplot() + 
  geom_point(aes(x = yardline_100, y = rushing_yards), alpha = 0.2) + 
  geom_smooth(aes(x = yardline_100, y = rushing_yards))
```

Let's bin and average to gain better insight.

```{r}
pbp_run %>%
  group_by(yardline_100) %>%
  summarize(
    avg_rush_yds = mean(rushing_yards)
  ) %>%
  ggplot() + 
  geom_point(aes(x = yardline_100, y = avg_rush_yds))
```

Seems like there is an association here. Let's plot score differential and rushing yards.

```{r}
pbp_run %>%
  group_by(score_differential) %>%
  summarize(
    avg_rush_yds = mean(rushing_yards)
  ) %>%
  ggplot() + 
  geom_point(aes(x = score_differential, y = avg_rush_yds)) + 
  geom_smooth(aes(x = score_differential, y = avg_rush_yds),
              method = "lm")
```

Okay, let's build a multiple linear regression model to predict rushing yards. We'll include `down`, `ydstogo`, an interaction between those variables, `yardline_100`, `run_location`, and `score_differential`.

```{r}
lin_reg_spec <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

lin_reg_rec <- recipe(rushing_yards ~ down + ydstogo + yardline_100 + run_location + score_differential, data = pbp_run) %>%
  step_mutate(down = as.factor(down)) %>%
  step_dummy(down) %>%
  step_interact(~starts_with("down"):ydstogo)

lin_reg_wf <- workflow() %>%
  add_model(lin_reg_spec) %>%
  add_recipe(lin_reg_rec)

lin_reg_fit <- lin_reg_wf %>%
  fit(pbp_run)

lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

Now that we have out model, we can compute the *rushing yards over expected* (residual) for each play.

```{r}
lin_reg_fit %>%
  augment(pbp_run) %>%
  mutate(ryoe = rushing_yards - .pred) %>%
  arrange(-ryoe)
```

Let's calculate RYOE by season, for each rusher.

```{r}
lin_reg_fit %>%
  augment(pbp_run) %>%
  mutate(ryoe = rushing_yards - .pred) %>%
  group_by(season, rusher_id, rusher) %>%
  summarize(
    total_rushes = n(),
    avg_rush_yds = mean(rushing_yards),
    avg_ryoe = mean(ryoe),
    total_rush_yds = sum(rushing_yards),
    total_ryoe = sum(ryoe),
    .groups = "drop"
    ) %>%
  filter(total_rushes > 50) %>%
  arrange(-avg_ryoe)
```

We can now try calculating the stability of average and total rushing yards as well as the stability of average and total ryoe.

```{r}
lin_reg_fit %>%
  augment(pbp_run) %>%
  mutate(ryoe = rushing_yards - .pred) %>%
  group_by(season, rusher_id, rusher) %>%
  summarize(
    total_rushes = n(),
    avg_rush_yds = mean(rushing_yards),
    avg_ryoe = mean(ryoe),
    total_rush_yds = sum(rushing_yards),
    total_ryoe = sum(ryoe),
    .groups = "drop"
    ) %>%
  filter(total_rushes > 50) %>%
  group_by(rusher_id, rusher) %>%
  mutate(
    next_total_rushes = lead(total_rushes),
    next_avg_rush_yds = lead(avg_rush_yds),
    next_avg_ryoe = lead(avg_ryoe),
    next_total_rush_yds = lead(total_rush_yds),
    next_total_ryoe = lead(total_ryoe)
  ) %>%
  ungroup() %>%
  filter(!is.na(next_total_rushes)) %>%
  summarize(
    cor_total_rushes = cor(total_rushes, next_total_rushes),
    cor_avg_rush_yards = cor(avg_rush_yds, next_avg_rush_yds),
    cor_avg_ryoe = cor(avg_ryoe, next_avg_ryoe),
    cor_total_rush_yds = cor(total_rush_yds, next_total_rush_yds),
    cor_total_ryoe = cor(total_ryoe, next_total_ryoe)
  )
```

We can see that average ryoe is slightly more stable that average rushing yards.

The remainder of the chapter goes into model assessment techniques. They look at residuals versus fitted values, the Q-Q plot, a scale-location plot, and the leverage plot (these are the four plots produced when you use `plot()` on a model). The authors advocate that looking at these plots can help us identify significant limitations about out model. For example, the model here fit quite poorly for runs less than 15 yards and runs over 95 yards. They filtered these observations out and then re-fit the model. 

:::{.callout-note}
I wonder how useful this is though, because you are eliminating most runs from the data used to fit the model.
:::

### Exercises

1. Change the *carries* threshold from 50 to 100 for the calculations of the stability measures (correlation) for each of the rusher performance summary statistics. Do we still see the same stability differences?
2. Us the full `nflfastR` dataset to show that rushing is less efficient than passing, both using yards per play and EPA (expected points added) per play. Also inspect the variability of these two play types.
3. Is rushing more valuable than passing in some situations? For example in late-down and short yardage situations, or plays near the opponent's goal line.
4. Inspect James Conner's RYOE values for his career relative to Le`Veon Bell's. What do you notice about the metric for both backs?
5. Repeat everything in this chapter for passing plays instead of running plays. You may want to use different features in the model (for example, `run_location` is not meaningful for passing plays).

## Chapter 5: GLMs and Completion Percentage Over Expected (CPOE)

```{r}
rm(list = ls())
```

```{r}
pbp_16_22 <- load_pbp(2016:2022)

pbp_pass <- pbp_16_22 %>%
  filter((play_type == "pass") & (!is.na(passer_id)) & (!is.na(air_yards)))

p1 <- pbp_pass %>%
  group_by(air_yards) %>%
  summarize(
    completion_pct = mean(complete_pass)
    ) %>%
  ggplot(aes(x = air_yards, y = completion_pct)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(
    title = "All Pass Lengths"
  )

p2 <- pbp_pass %>%
  filter(between(air_yards, 0, 30)) %>%
  group_by(air_yards) %>%
  summarize(
    completion_pct = mean(complete_pass)
    ) %>%
  ggplot(aes(x = air_yards, y = completion_pct)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(
    title = "Passes Between 0 and 30 Yards"
  )

p1 + p2  
```

We'll build a simple logistic regression model for expected completion percentage, just using `air_yards` as the sole predictor.

```{r}
log_reg_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

log_reg_rec <- recipe(complete_pass ~ air_yards, data = pbp_pass) %>%
  step_mutate(complete_pass = as.factor(complete_pass))

log_reg_wf <- workflow() %>%
  add_model(log_reg_spec) %>%
  add_recipe(log_reg_rec)

log_reg_fit <- log_reg_wf %>%
  fit(pbp_pass)

log_reg_fit %>%
  glance()
```

```{r}
log_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

```{r}
log_reg_fit %>%
  augment(pbp_pass) %>%
  mutate(cpoe = complete_pass - .pred_1) %>%
  group_by(season, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    avg_pass_length = mean(air_yards),
    avg_cpoe = mean(cpoe),
    .groups = "drop") %>%
  filter(total_passes > 100) %>%
  arrange(-avg_cpoe) 
```

Let's build a model that can adjust for more complex game scenarios. We'll include `down` (as a factor), yards to go for a first down (`ydstogo`), the `yardline_100`, the `pass_location`, and `qb_hit`. We'll also include an interaction between `down` and `ydstogo`.

```{r}
log_reg_rec <- recipe(complete_pass ~ air_yards + down + ydstogo + yardline_100 + pass_location + qb_hit, data = pbp_pass) %>%
  step_mutate(complete_pass = as.factor(complete_pass)) %>%
  step_mutate(down = as.factor(down)) %>%
  step_mutate(qb_hit = as.factor(qb_hit)) %>%
  step_unknown(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_other(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_interact(~starts_with("down"):ydstogo)

log_reg_wf <- workflow() %>%
  add_model(log_reg_spec) %>%
  add_recipe(log_reg_rec)

log_reg_fit <- log_reg_wf %>%
  fit(pbp_pass)
```

```{r}
log_reg_fit %>%
  glance()
```

```{r}
log_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

Let's re-run our analysis on CPOE, but with this model adjusting for more game scenarios.

```{r}
log_reg_fit %>%
  augment(pbp_pass) %>%
  mutate(cpoe = complete_pass - .pred_1) %>%
  group_by(season, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    avg_pass_length = mean(air_yards),
    avg_cpoe = mean(cpoe),
    completion_pct = mean(complete_pass),
    .groups = "drop") %>%
  filter(total_passes > 100) %>%
  arrange(-avg_cpoe) 
```

Let's investigate the stability of CPOE versus completion percentage.

```{r}
log_reg_fit %>%
  augment(pbp_pass) %>%
  mutate(cpoe = complete_pass - .pred_1) %>%
  group_by(season, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    avg_pass_length = mean(air_yards),
    avg_cpoe = mean(cpoe),
    completion_pct = mean(complete_pass),
    .groups = "drop") %>%
  filter(total_passes > 100) %>%
  group_by(passer_id, passer) %>%
  arrange(season) %>%
  mutate(
    next_total_passes = lead(total_passes),
    next_cpoe = lead(avg_cpoe),
    next_completion_pct = lead(completion_pct)
  ) %>%
  ungroup() %>%
  filter(!is.na(next_total_passes)) %>%
  summarize(
    cor_total_passes = cor(total_passes, next_total_passes),
    cor_completion_pct = cor(completion_pct, next_completion_pct),
    cor_cpoe = cor(avg_cpoe, next_cpoe)
  )
```

Note that the numbers above don't exactly match the numbers suggested by the book. Completion percentage has a correlation of about 0.446 and CPOE has a correlation of about 0.465. Maybe because of how I'm treating novel categories? It also could be that they are using joins and I'm not. The result of my calculation ignores the possibility of a passer getting injured or benched during a season and not meeting my pass requirement threshold. I'll try the join approach from the book below.

```{r}
log_reg_fit %>%
  augment(pbp_pass) %>%
  mutate(cpoe = complete_pass - .pred_1) %>%
  group_by(season, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    avg_pass_length = mean(air_yards),
    avg_cpoe = mean(cpoe),
    completion_pct = mean(complete_pass),
    exp_completion_pct = mean(.pred_1),
    .groups = "drop") %>%
  filter(total_passes > 100) %>%
  group_by(passer_id, passer) %>%
  arrange(season) %>%
  mutate(
    next_season = lead(season),
    next_total_passes = lead(total_passes),
    next_cpoe = lead(avg_cpoe),
    next_completion_pct = lead(completion_pct),
    next_exp_completion_pct = lead(exp_completion_pct)
    ) %>%
  filter(next_season == season + 1) %>%
  ungroup() %>%
  filter(!is.na(next_total_passes)) %>%
  summarize(
    cor_total_passes = cor(total_passes, next_total_passes),
    cor_completion_pct = cor(completion_pct, next_completion_pct),
    cor_cpoe = cor(avg_cpoe, next_cpoe),
    cor_exp_completion_pct = cor(exp_completion_pct, next_exp_completion_pct)
  )
```

That's better. There are some things to note about this analysis, however. Some of the features and feature combinations included in the model could be associated with the Quarterback though. That is, the model may inadvertently account for differences in Quarterback quality, which then confounds our understanding of CPOE. We see that the correlation in expected completion percentage is higher than either completion percentage or CPOE, indicating that Quarterback play is relatively stable year-over-year.

### Discussion on Odds

```{r}
log_reg_fit %>% 
  extract_fit_engine() %>%
  tidy() %>%
  mutate(
    lower_odds = exp(estimate - (2*std.error)),
    odds = exp(estimate),
    upper_odds = exp(estimate + (2*std.error))
    )
```

From the tabular output above, we can see that passes to the middle of the field are about 1.21 times more likely to be completed than passes to the left or right sidelines. Similarly, each additional yard to go decreases the baseline (intercept) odds of completion by a factor of about 0.9443. For example, the baseline (intercept) odds for a pass with a single yard to go is about $2.0506\cdot 0.9443$, or 1.936, which a pass with nine yards to go has completion odds of about $2.0506\times \left(0.9442^9\right)$, or 1.224.

For any singular pass, we can also calculate the expected odds of completion. This can be useful for evaluating real-time game scenarios and play-calling.

```{r}
log_reg_fit %>% 
  augment(pbp_pass) %>%
  mutate(
    odds = .pred_1 / (1 - .pred_1)
  ) %>%
  select(down, ydstogo, yardline_100, air_yards, qb_hit, odds)
```

### Exercises

1. Reproduce this analysis without the `qb_hit` feature. How does it change the leaderboard and what can we take away?
2. What other features could/should be added to our logistic regression? How do these adjustments change the stability estimates.
3. Try the analysis for receivers instead of Quarterbacks -- does anything interesting emerge?
4. Try is again for defensive positions.

## Chapter 6: Poisson Regression and Passing Touchdowns







