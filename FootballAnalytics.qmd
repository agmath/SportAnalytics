---
title: "Football Analytics"
author: "Adam Gilbert"
format: html
theme: flatly
date: today
toc: true
---

## Introduction

This notebook contains sections corresponding to the textbook *Football Analytics with Python & R*, by Eric A. Eager and Richard A. Erickson. I include a subsection in this notebook for each chapter of the text, and include solutions to exercises as well as some explorations of different questions I thought may be interesting to explore.

## Chapter 1: Football Analytics

This introductory chapter provides the reader an introduction to R and Python as well as to the `{nflfastR}` package in R (and the `nfl_data_py` Python module). I'll be working through the textbook in R, since that is my preferred language.

```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(kableExtra)
library(nflfastR)
library(patchwork)
library(tidymodels)
```

We can load *play-by-play* data using the `load_pbp()` function from this package. I'll load the data from the 2021 season, as shown in the textbook.

```{r}
pbp_21 <- load_pbp(2021)

pbp_21 %>%
  head(n = 2) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

This collection of play-by-play data from the 2021 season includes `r pbp_21 %>% nrow()` observations on `r pbp_21 %>% ncol()` variables. The text guides us through a simple example of ranking quarterbacks by their level of *agressivity*, as defined by average pass depth (`air_yards`). In order to perform this analysis, we'll filter to include only pass plays with recorded `air_yards` values. After computing the summary statistics, we filter out unknown passers and passers who attempted very few passes.

```{r}
pbp_21 %>%
  filter((play_type == "pass") & (!is.na(air_yards))) %>%
  group_by(passer_id, passer) %>%
  summarize(num_passes = n(), avg_depth_of_pass = mean(air_yards),
            .groups = "drop") %>%
  filter((num_passes >= 100) & (!is.na(passer))) %>%
  arrange(-avg_depth_of_pass) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

The below plots show pass depth distributons for each of the top fifteen quarterbacks listed above.

```{r}
deepest_passers <- pbp_21 %>%
  filter((play_type == "pass") & (!is.na(air_yards))) %>%
  group_by(passer_id, passer) %>%
  summarize(num_passes = n(), avg_depth_of_pass = mean(air_yards),
            .groups = "drop") %>%
  filter((num_passes >= 100) & (!is.na(passer))) %>%
  arrange(-avg_depth_of_pass) %>%
  slice_max(avg_depth_of_pass, n = 15) %>%
  pull(passer)

pbp_21 %>%
  filter((play_type == "pass") & (!is.na(air_yards)) & (passer %in% deepest_passers)) %>%
  mutate(passer = factor(passer, levels = deepest_passers)) %>%
  ggplot() + 
  geom_density(aes(x = air_yards, fill = passer), show.legend = FALSE) + 
  geom_boxplot(aes(x = air_yards, y = -0.02, fill = passer), width = 0.01, show.legend = FALSE) + 
  facet_wrap(~passer, nrow = 3) + 
  labs(title = "Pass Depth Distributions for 2021's Deepest Average Passers",
       x = "Air Yards",
       y = "")
```

It is interesting how similar these distributions look. Drew Lock had the highest average `air_depth` but he also had the fewest total passes among this group. This means that those very few deep-ball outliers had greater influence on his average pass depth than the other quarterbacks who played more snaps.

## Chapter 2: EDA through Stable Versus Unstable QB Stats

The authors include an interesting discussion on how players should be evaluated. Some statistical measures are relatively stable for players year-over-year, while others include more variability. This introduces the possibility for strategic trading on high-variability measures -- we can *sell-high* and *buy-low* on players based on such performance measures if other teams are placing undue weight on these high-variance and unstable stats. For example, yards gained by a running back are not generally stable and neither are yards gained as a result of deep throws from a quarterback. Yards gained by short passes, however, are generally stable year-over-year. Let's analyse some of these ideas. 

In the text, the authors use EDA to explore the hypothesis: *Throwing deep passes is more valuable than short passes, but it is difficult to say whether a quarterback is "good" at deep passes*. Here, the variability comes in with the latter half of the hypothesis -- determining whether a quarterback excels in deep passing is difficult because of the high variability in deep passing statistics year-over-year.

Since we are discussing year-over-year comparisons, we'll need to load several seasons-worth of data. We'll do that now.

```{r}
pbp_16_21 <- load_pbp(2016:2021)
```

We've got a lot more data to deal with now. Certainly, the number of features (variables) has stayed the same, but now we have `r pbp_16_21 %>% nrow()` observations across the six seasons. The authors justify looking at 2016 to 2021 because the beginning of the 2016 season was the last time a major rule change was implemented. A touchback on a kickoff resulted in starting from the 25 yard line rather than the 20 yard line. This rule change resulted in a change in kickoff strategy across the league, so analysing pre- and post-2016 data separately is justifiable.

Let's take a look at year-over-year short and long pass results. We'll use the `air_yards` variable to separate pass attempts into *long* (at least 20 yards) and *short* (less than 20 yards), and start with some simple numeric summaries, looking at *expected points added` (`epa`) by long/short pass plays.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass",
         !(is.na(air_yards))) %>%
  mutate(passing_yards = ifelse(is.na(passing_yards), 0, passing_yards),
         pass_type = ifelse(air_yards >= 20, "long", "short")) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  group_by(pass_type) %>%
  summarize(
    min_epa = min(epa, na.rm = TRUE),
    q1_epa = quantile(epa, 0.25, na.rm = TRUE),
    med_epa = median(epa, na.rm = TRUE),
    mean_epa = mean(epa, na.rm = TRUE),
    q3_epa = quantile(epa, 0.75, na.rm = TRUE),
    max_epa = max(epa, na.rm = TRUE),
    iqr_epa = IQR(epa, na.rm = TRUE),
    sd_epa = sd(epa, na.rm = TRUE),
    missing_count = sum(is.na(epa)),
    .groups = "drop"
  ) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

We can see that expected points added has greater variation on long pass plays than it does on short pass plays.

We'll build a plot to compare passing stats between pairs of consecutive years, investigating stability of `passing_yards`. Let's start by simply drawing the distributions of passing yards resulting from long and short pass plays.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
         passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_histogram(aes(x = passing_yards, y = ..density.., fill = pass_type), 
                 binwidth = 1, color = "black", show.legend = FALSE) +
  #geom_density(aes(x = passing_yards, fill = pass_type),
  #             alpha = 0.4, show.legend = FALSE) + 
  geom_boxplot(aes(x = passing_yards, y = -0.02, fill = pass_type), 
               width = 0.01, show.legend = FALSE) + 
  labs(
    title = "Distribution of Passing Yards by Pass Type",
    x = "Passing Yards",
    y = ""
  ) + 
  facet_wrap(~pass_type)
```

We can see that lots of pass plays in general do not result in catches. Long passes, however, are much less likely to result in a completion. Interestingly, the distribution of passing yards on short passes, looks to be normally distributed when dropped balls are omitted.

Now that we have these insights, let's take a look at the distributions of expected points added on these plays as well.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
         passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_histogram(aes(x = epa, y = ..density.., fill = pass_type), 
                 bins = 50, color = "black", show.legend = FALSE) +
  geom_density(aes(x = epa, fill = pass_type),
               alpha = 0.4, show.legend = FALSE) + 
  geom_boxplot(aes(x = epa, y = -0.02, fill = pass_type), 
               width = 0.01, show.legend = FALSE) + 
  labs(
    title = "Distribution of Expected Points Added by Pass Type",
    x = "Passing Yards",
    y = ""
  ) + 
  facet_wrap(~pass_type)
```

From the plots above, we again see that the long passes show greater variability in terms of expected points added. On average, the `epa` values here are lower than for short passes, however we do see that when long passes result in receptions [assumedly], the `epa` values are much greater.

Now let's see whether average passing yards on short- and long- passing attemps are stable metrics year over year. We'll remove passers that threw very few attempts in a season, since these often include non-QB players throwing passes on trick plays that may end up in very large gains.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
         passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            avg_pass_yards = mean(passing_yards),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
             passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                avg_pass_yards = mean(passing_yards),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(avg_pass_yards_curr = avg_pass_yards.x,
         avg_pass_yards_next = avg_pass_yards.y) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_point(aes(x = avg_pass_yards_curr, y = avg_pass_yards_next)) + 
  geom_smooth(aes(x = avg_pass_yards_curr, y = avg_pass_yards_next),
              method = "lm") + 
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") + 
  facet_wrap(~pass_type) + 
  labs(
    title = "Year-to-Year Stability of Passing Yards",
    x = "Current Year Passing Yards",
    y = "Next Year Passing Yards"
  )
```

We can see that there is a positive correlation between year over year passing yards. That correlation looks to be stronger on short passes. Let's see this numerically below.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
         passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            avg_pass_yards = mean(passing_yards),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short"),
             passing_yards = ifelse(is.na(passing_yards), 0, passing_yards)) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                avg_pass_yards = mean(passing_yards),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(avg_pass_yards_curr = avg_pass_yards.x,
         avg_pass_yards_next = avg_pass_yards.y) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  group_by(pass_type) %>%
  summarize(y2y_avg_pass_yards_correlation = cor(avg_pass_yards_curr, avg_pass_yards_next)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

### Homework Exercises

The following are the exercises at the end of this chapter.

1. Create histograms using `epa` (Expected Points Added) per pass attempt.

> I ended up doing this earlier in the *notes* section.

2. Create boxplots using `epa` per pass attempt.

> I also ended up doing this earlier in the *notes* section.

3. Perform the stability analysis for average `epa` per pass attempt. Interpret the results. Do any players have similar yards per attempt year over year, but quite different EPA values? Where could this come from?

> In the plot below, I'll compare average EPA values for consecutive years. I'll add player names to the plot in any cases where the average EPA for consecutive years differed by a full point or more.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            avg_epa = mean(epa, na.rm = TRUE),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                avg_epa = mean(epa, na.rm = TRUE),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(avg_epa_curr = avg_epa.x,
         avg_epa_next = avg_epa.y) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_point(aes(x = avg_epa_curr, y = avg_epa_next)) + 
  geom_smooth(aes(x = avg_epa_curr, y = avg_epa_next),
              method = "lm") + 
  geom_text(aes(x = avg_epa_curr, y = avg_epa_next, label = ifelse(abs(avg_epa_curr - avg_epa_next) > 1, passer, ""))) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") + 
  facet_wrap(~pass_type) + 
  labs(
    title = "Year-to-Year Stability of Expected Points Added",
    x = "Current Year Average EPA",
    y = "Next Year Average EPA"
  )
```

> Similar to what we did with the year-over-year passing yards, we'll compute the correlation between consecutive year average EPA per pass attempt for long and short passes.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            avg_epa = mean(epa, na.rm = TRUE),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                avg_epa = mean(epa, na.rm = TRUE),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(avg_epa_curr = avg_epa.x,
         avg_epa_next = avg_epa.y) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  group_by(pass_type) %>%
  summarize(y2y_avg_epa_correlation = cor(avg_epa_curr, avg_epa_next)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

> The correlation here is still stronger for *short* passes than *long* pass attempts. To answer the remaining question about players with stable YPA values, but unstable EPA values, I'll compute the change in YPA over consecutive years and do the same with the change in EPA per attempt over consecutive years. Then I'll plot the results and identify players far from the 45-degree diagonal.

```{r}
pbp_16_21 %>%
  filter(play_type == "pass", !(is.na(air_yards))) %>%
  mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
  group_by(passer_id, passer, season, pass_type) %>%
  summarize(passing_attempts = n(),
            ypa = mean(passing_yards, na.rm = TRUE),
            avg_epa = mean(epa, na.rm = TRUE),
            .groups = "drop") %>%
  filter(passing_attempts >= 10) %>%
  mutate(next_season = season + 1) %>%
  inner_join(
    pbp_16_21 %>%
      filter(play_type == "pass", !(is.na(air_yards))) %>%
      mutate(pass_type = ifelse(air_yards > 20, "long", "short")) %>%
      group_by(passer_id, passer, season, pass_type) %>%
      summarize(passing_attempts = n(),
                ypa = mean(passing_yards, na.rm = TRUE),
                avg_epa = mean(epa, na.rm = TRUE),
              .groups = "drop") %>%
      filter(passing_attempts >= 10),
      by = c("passer_id" = "passer_id", 
           "passer" = "passer",
           "next_season" = "season",
           "pass_type" = "pass_type")
  ) %>%
  rename(ypa_curr = ypa.x,
         ypa_next = ypa.y,
         avg_epa_curr = avg_epa.x,
         avg_epa_next = avg_epa.y) %>%
  mutate(ypa_delta = ypa_next - ypa_curr,
         avg_epa_delta = avg_epa_next - avg_epa_curr) %>%
  mutate(pass_type = factor(pass_type, levels = c("short", "long"))) %>%
  ggplot() + 
  geom_point(aes(x = ypa_delta, y = avg_epa_delta)) + 
  geom_text(aes(x = ypa_delta, y = avg_epa_delta, label = ifelse(abs(avg_epa_delta) > 1, passer, ""))) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") + 
  facet_wrap(~pass_type) + 
  labs(
    title = "Change in YPA with Change in Average EPA",
    x = "Change in YPA",
    y = "Change in Average EPA"
  )
```

> WIth the exception of Tua, these look like players who have switched teams fairly often throughout their careers. A switch in team means a switch in coaching staff and strategy. We could plot the year in addition to the player name and then check on this hypothesis if we wanted.

4. Find a cutoff that equally splits the data between *long* and *short* pass attempts and then re-run the analysis. 

> I'm not going to repeat the analysis right now, but we can find the median pass attempt length to determine a more equitable cutoff than 20 yards for `air_yards`. That cutoff would be about `r round(median(pbp_16_21$air_yards, na.rm = TRUE), 1)`.

## Chapter 3: Linear Regression and Rushing Yards Over Expected

We'll continue with the 2016 - 2021 play-by-play data in this chapter. Here, however, we'll focus on rushing yards. The main ideas presented are quite interesting -- basically, not all rushes are created equally. If a rusher gains 6 yards, when 8 are needed, then they did not achieve their objective. However, if a rusher gains 2 yards on a 3rd and 1, then that rusher has done their job and the play was successful. We need ways to assess the quality of a play, while controlling for the current game conditions -- for example, down and yards to go.

Let's start by looking at the relationship between yards to gain (yards to a first down or touchdown) and the rushing yards gained on a running play.

```{r}
pbp_16_21 %>%
  count(play_type)

p1 <- pbp_16_21 %>%
  filter(play_type == "run") %>%
  ggplot() + 
  geom_point(aes(x = ydstogo, y = rushing_yards), alpha = 0.25) + 
  geom_smooth(aes(x = ydstogo, y = rushing_yards), method = "lm") + 
  labs(title = "Rushing Yards Gained versus Yards to Go",
       x = "Yards to Go",
       y = "Rushing Yards Gained")

p2 <- pbp_16_21 %>%
  filter(play_type == "run") %>%
  ggplot() + 
  geom_boxplot(aes(x = ydstogo, y = rushing_yards, group = ydstogo)) + 
  geom_smooth(aes(x = ydstogo, y = rushing_yards), method = "lm") + 
  labs(title = "Rushing Yards Gained versus Yards to Go",
       x = "Yards to Go",
       y = "Rushing Yards Gained")

p1 + p2
```

This is really noisy data. Let's see if we can get some better insight by averaging the number of rushing yards gained at each yards-to-go threshold.

```{r}
pbp_16_21 %>%
  filter(play_type == "run") %>%
  group_by(ydstogo) %>%
  summarize(avg_rush_gain = mean(rushing_yards)) %>%
  ggplot() + 
  geom_point(aes(x = ydstogo, y = avg_rush_gain)) + 
  geom_smooth(aes(x = ydstogo, y = avg_rush_gain), method = "lm") + 
  labs(title = "Average Rush Yards Gained by Yards to Go",
       x = "Yards to Go",
       y = "Average Rushing Yards Gained")
```

Let's build and analyse a simple linear regression model to predict rushing yards gained, by the current yards to go.

```{r}
lin_reg_spec <- linear_reg() %>%
  set_engine("lm")

lin_reg_rec <- recipe(rushing_yards ~ ydstogo, data = pbp_16_21)

lin_reg_wf <- workflow() %>%
  add_model(lin_reg_spec) %>%
  add_recipe(lin_reg_rec)

lin_reg_fit <- lin_reg_wf %>%
  fit(pbp_16_21)
```

Now that we have a fitted model, we can see the global model utility metrics below.

```{r}
lin_reg_fit %>%
  glance() %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Similarly, we can see the statistical measures on the individual model terms below as well.

```{r}
lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

We can now use our model to obtain residuals and explore Rushing Yards Over Expected (RYOE).

```{r}
lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run") %>%
      select(rusher, ydstogo, rushing_yards)
  ) %>%
  mutate(RYOE = .pred - rushing_yards) %>%
  ggplot() + 
  geom_point(aes(x = ydstogo, y = RYOE)) + 
  geom_text(aes(x = ydstogo, y = RYOE, label = ifelse(RYOE > quantile(RYOE, 0.9999, na.rm = TRUE), rusher, ""))) + 
  ylim(c(0, 40)) +
  labs(title = "Most Successful Rushes",
       x = "Yards to Gain",
       y = "Rushing Yards Over Expected")
```

Notice that those rushes which are longer than expected seemed to occur on yardages typically thought of as throwing situations. These were relatively long-yardage scenarios.

Let's dive deeper into RYOE, and understand which players had the highest average RYOE in each season. We'll then determine the stability of the RYOE metric from one year to the next, similarly to the way we determined the stability of passing yards on short- and long- passes in the previous chapter.

```{r}
lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run", !is.na(rusher)) %>%
      select(rusher_id, rusher, season, ydstogo, rushing_yards) %>%
      mutate(rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)) 
    ) %>%
  rename(expected_yards = .pred) %>%
  mutate(ryoe = rushing_yards - expected_yards) %>%
  group_by(rusher_id, rusher, season) %>%
  summarize(
    runs = n(),
    avg_ryoe = mean(ryoe),
    avg_rush_yards = mean(rushing_yards),
    total_ryoe = sum(ryoe),
    total_rush_yards = sum(rushing_yards),
    .groups = "drop"
  ) %>%
  filter(runs >= 50) %>%
  arrange(-avg_ryoe) %>%
  head(n = 20) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

As in the textbook, we see several Quarterbacks at the top of the list. In particular, Lamar Jackson had several great seasons, as measured by RYOE. This is part of what led to him being given an enormous contract in 2023.

If we arrange rushers by `total_ryoe` rather than `avg_ryoe`, we see the following results.

```{r}
lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run", !is.na(rusher)) %>%
      select(rusher_id, rusher, season, ydstogo, rushing_yards) %>%
      mutate(rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)) 
    ) %>%
  rename(expected_yards = .pred) %>%
  mutate(ryoe = rushing_yards - expected_yards) %>%
  group_by(rusher_id, rusher, season) %>%
  summarize(
    runs = n(),
    avg_ryoe = mean(ryoe),
    avg_rush_yards = mean(rushing_yards),
    total_ryoe = sum(ryoe),
    total_rush_yards = sum(rushing_yards),
    .groups = "drop"
  ) %>%
  filter(runs >= 50) %>%
  arrange(-total_ryoe) %>%
  head(n = 20) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Again, like the text, we see Jonathan Taylor and Derrick Henry topping this list.

Now let's see whether `avg_ryoe` and `total_ryoe` are stable metrics from one year to the next.

```{r}
rush_stats_16_21 <- lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run", !is.na(rusher)) %>%
      select(rusher_id, rusher, season, ydstogo, rushing_yards) %>%
      mutate(rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)) 
    ) %>%
  rename(expected_yards = .pred) %>%
  mutate(ryoe = rushing_yards - expected_yards) %>%
  group_by(rusher_id, rusher, season) %>%
  summarize(
    runs = n(),
    avg_ryoe = mean(ryoe),
    avg_rush_yards = mean(rushing_yards),
    total_ryoe = sum(ryoe),
    total_rush_yards = sum(rushing_yards),
    .groups = "drop"
  ) %>%
  filter(runs > 50) %>%
  mutate(next_season = season + 1) %>%
  select(rusher_id, rusher, season, next_season, runs, avg_ryoe, 
         avg_rush_yards, total_ryoe, total_rush_yards)

rush_stats_16_21 %>%
  select(-season) %>%
  inner_join(
    rush_stats_16_21 %>%
      select(-next_season),
    by = c("rusher_id" = "rusher_id", "rusher" = "rusher", "next_season" = "season")
    ) %>%
    summarize(
      rushes = cor(runs.x, runs.y),
      avg_ryoe = cor(avg_ryoe.x, avg_ryoe.y),
      avg_rush_yds = cor(avg_rush_yards.x, avg_rush_yards.y),
      total_ryoe = cor(total_ryoe.x, total_ryoe.y),
      total_rush_yds = cor(total_rush_yards.x, total_rush_yards.y)
    ) %>%
  pivot_longer(cols = everything(), names_to = "metric", values_to = "y2y_correlation") %>%
  arrange(-y2y_correlation) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

Notice that `total_rush_yds`, and `total_ryoe` are difficult to interpret because volume is a masked variable in both of these measures. These metrics actually measure two things -- the frequency of run attempts and the length of each run. We aren't reproducing the exact numbers from the textbook here. I'm wondering if that is due to stat updates, or if my code is not identical to the code found in the text.

### Exercises

1. What happens if you repeat the correlation analysis, but use 100 rushes per season as the threshold rather than 50? Are the takeaways regarding stability the same?

```{r}
rush_stats_16_21 <- lin_reg_fit %>%
  augment(
    pbp_16_21 %>%
      filter(play_type == "run", !is.na(rusher)) %>%
      select(rusher_id, rusher, season, ydstogo, rushing_yards) %>%
      mutate(rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)) 
    ) %>%
  rename(expected_yards = .pred) %>%
  mutate(ryoe = rushing_yards - expected_yards) %>%
  group_by(rusher_id, rusher, season) %>%
  summarize(
    runs = n(),
    avg_ryoe = mean(ryoe),
    avg_rush_yards = mean(rushing_yards),
    total_ryoe = sum(ryoe),
    total_rush_yards = sum(rushing_yards),
    .groups = "drop"
  ) %>%
  filter(runs > 100) %>%
  mutate(next_season = season + 1) %>%
  select(rusher_id, rusher, season, next_season, runs, avg_ryoe, 
         avg_rush_yards, total_ryoe, total_rush_yards)

rush_stats_16_21 %>%
  select(-season) %>%
  inner_join(
    rush_stats_16_21 %>%
      select(-next_season),
    by = c("rusher_id" = "rusher_id", "rusher" = "rusher", "next_season" = "season")
    ) %>%
    summarize(
      rushes = cor(runs.x, runs.y),
      avg_ryoe = cor(avg_ryoe.x, avg_ryoe.y),
      avg_rush_yds = cor(avg_rush_yards.x, avg_rush_yards.y),
      total_ryoe = cor(total_ryoe.x, total_ryoe.y),
      total_rush_yds = cor(total_rush_yards.x, total_rush_yards.y)
    ) %>%
  pivot_longer(cols = everything(), names_to = "metric", values_to = "y2y_correlation") %>%
  arrange(-y2y_correlation) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

> We do see that `avg_ryoe` is still a more stable measure than `avg_rush_yds` from one year to the next. The different in correlations is similar -- about $0.016$ versus $0.013$ -- although, this is about a 23% increase in the difference. Interestingly, we see that the correlation between total runs and total rush yards from year to year has dropped significantly. This indicates that dominant rushers (rushers getting lots of carries) don't generally hold over from one year to the next. This could be due to wear and tear on the position.

2. Assume that all of Mike Alstott's carries were on 3rd and 1 situations, while all Warrick Dunn's carries were on 1st and 10s. Is situation alone enough to explain the difference between the yards per carry for these two players (3.7 yards per carry versus 4.0 yards per carry)?

```{r}
lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy() %>%
  kable() %>%
  kable_styling(bootstrap_options = c("hover", "striped"))
```

> Notice that the coefficient on yards to go in the regression model is about 0.113. If we multiply this by 9 (the difference in the assumed yards to go measures), we expect a difference of about a full yard (in terms of expected rushing yards). This would be more than enough to explain the difference in yards per carry for these two backs.

3. What happens if you repeat the analyses in the chapter with yards to the endzone (`yard_line_100`) rather than yards to gain?

> I'm omitting this for now, but it should be simple to do.

4. Conduct an analysis analogous to the one in this chapter, but for receivers and the passing game.

> Again, I'm omitting for now, but it should be easy to conduct.

## Chapter 4: Multiple Linear Regression and Rushing Yards Over Expected, Revisited

In Chapter 3, we controlled for just a single variable. However, the result of a rushing play is almost surely to depend on more than simply the *yards to gain*. For example, A 2nd and 1 is a very different play than a 4th and 1. In the former, the defense may expect a long passing play and needs to defend against that, while in the latter, it is much more likely that the offense will simply try to reach the line to gain and so defenses in these situations are defending primarily against short plays.

In this chapter, we'll build our regression model to control for more gameplay scenarios.

```{r}
pbp_16_22 <- load_pbp(2016:2022)

pbp_run <- pbp_16_22 %>%
  filter((play_type == "run") & (!is.na(rusher_id)) & (!is.na(down)) & (!is.na(run_location))) %>%
  mutate(
    rushing_yards = ifelse(is.na(rushing_yards), 0, rushing_yards)
  )

pbp_run %>%
  ggplot() + 
  geom_density(aes(x = rushing_yards, fill = run_location)) +
  facet_grid(down ~ run_location) + 
  theme_bw() +
  theme(legend.position = "none")
```

```{r}
p_all_runs <- pbp_run %>%
  ggplot() + 
  geom_boxplot(aes(x = down, y = rushing_yards, group = down))

p_ten_to_run <- pbp_run %>%
  filter(ydstogo == 10) %>%
  ggplot() + 
  geom_boxplot(aes(x = down, y = rushing_yards, group = down))

p_all_runs + p_ten_to_run
```

Let's plot rushing yards gained against the starting yard line for the play.

```{r}
pbp_run %>%
  ggplot() + 
  geom_point(aes(x = yardline_100, y = rushing_yards), alpha = 0.2) + 
  geom_smooth(aes(x = yardline_100, y = rushing_yards))
```

Let's bin and average to gain better insight.

```{r}
pbp_run %>%
  group_by(yardline_100) %>%
  summarize(
    avg_rush_yds = mean(rushing_yards)
  ) %>%
  ggplot() + 
  geom_point(aes(x = yardline_100, y = avg_rush_yds))
```

Seems like there is an association here. Let's plot score differential and rushing yards.

```{r}
pbp_run %>%
  group_by(score_differential) %>%
  summarize(
    avg_rush_yds = mean(rushing_yards)
  ) %>%
  ggplot() + 
  geom_point(aes(x = score_differential, y = avg_rush_yds)) + 
  geom_smooth(aes(x = score_differential, y = avg_rush_yds),
              method = "lm")
```

Okay, let's build a multiple linear regression model to predict rushing yards. We'll include `down`, `ydstogo`, an interaction between those variables, `yardline_100`, `run_location`, and `score_differential`.

```{r}
lin_reg_spec <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

lin_reg_rec <- recipe(rushing_yards ~ down + ydstogo + yardline_100 + run_location + score_differential, data = pbp_run) %>%
  step_mutate(down = as.factor(down)) %>%
  step_dummy(down) %>%
  step_interact(~starts_with("down"):ydstogo)

lin_reg_wf <- workflow() %>%
  add_model(lin_reg_spec) %>%
  add_recipe(lin_reg_rec)

lin_reg_fit <- lin_reg_wf %>%
  fit(pbp_run)

lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

Now that we have out model, we can compute the *rushing yards over expected* (residual) for each play.

```{r}
lin_reg_fit %>%
  augment(pbp_run) %>%
  mutate(ryoe = rushing_yards - .pred) %>%
  arrange(-ryoe)
```

Let's calculate RYOE by season, for each rusher.

```{r}
lin_reg_fit %>%
  augment(pbp_run) %>%
  mutate(ryoe = rushing_yards - .pred) %>%
  group_by(season, rusher_id, rusher) %>%
  summarize(
    total_rushes = n(),
    avg_rush_yds = mean(rushing_yards),
    avg_ryoe = mean(ryoe),
    total_rush_yds = sum(rushing_yards),
    total_ryoe = sum(ryoe),
    .groups = "drop"
    ) %>%
  filter(total_rushes > 50) %>%
  arrange(-avg_ryoe)
```

We can now try calculating the stability of average and total rushing yards as well as the stability of average and total ryoe.

```{r}
lin_reg_fit %>%
  augment(pbp_run) %>%
  mutate(ryoe = rushing_yards - .pred) %>%
  group_by(season, rusher_id, rusher) %>%
  summarize(
    total_rushes = n(),
    avg_rush_yds = mean(rushing_yards),
    avg_ryoe = mean(ryoe),
    total_rush_yds = sum(rushing_yards),
    total_ryoe = sum(ryoe),
    .groups = "drop"
    ) %>%
  filter(total_rushes > 50) %>%
  group_by(rusher_id, rusher) %>%
  mutate(
    next_total_rushes = lead(total_rushes),
    next_avg_rush_yds = lead(avg_rush_yds),
    next_avg_ryoe = lead(avg_ryoe),
    next_total_rush_yds = lead(total_rush_yds),
    next_total_ryoe = lead(total_ryoe)
  ) %>%
  ungroup() %>%
  filter(!is.na(next_total_rushes)) %>%
  summarize(
    cor_total_rushes = cor(total_rushes, next_total_rushes),
    cor_avg_rush_yards = cor(avg_rush_yds, next_avg_rush_yds),
    cor_avg_ryoe = cor(avg_ryoe, next_avg_ryoe),
    cor_total_rush_yds = cor(total_rush_yds, next_total_rush_yds),
    cor_total_ryoe = cor(total_ryoe, next_total_ryoe)
  )
```

We can see that average ryoe is slightly more stable that average rushing yards.

The remainder of the chapter goes into model assessment techniques. They look at residuals versus fitted values, the Q-Q plot, a scale-location plot, and the leverage plot (these are the four plots produced when you use `plot()` on a model). The authors advocate that looking at these plots can help us identify significant limitations about out model. For example, the model here fit quite poorly for runs less than 15 yards and runs over 95 yards. They filtered these observations out and then re-fit the model. 

:::{.callout-note}
I wonder how useful this is though, because you are eliminating most runs from the data used to fit the model.
:::

### Exercises

1. Change the *carries* threshold from 50 to 100 for the calculations of the stability measures (correlation) for each of the rusher performance summary statistics. Do we still see the same stability differences?
2. Us the full `nflfastR` dataset to show that rushing is less efficient than passing, both using yards per play and EPA (expected points added) per play. Also inspect the variability of these two play types.
3. Is rushing more valuable than passing in some situations? For example in late-down and short yardage situations, or plays near the opponent's goal line.
4. Inspect James Conner's RYOE values for his career relative to Le`Veon Bell's. What do you notice about the metric for both backs?
5. Repeat everything in this chapter for passing plays instead of running plays. You may want to use different features in the model (for example, `run_location` is not meaningful for passing plays).

## Chapter 5: GLMs and Completion Percentage Over Expected (CPOE)

```{r}
rm(list = ls())
```

```{r}
pbp_16_22 <- load_pbp(2016:2022)

pbp_pass <- pbp_16_22 %>%
  filter((play_type == "pass") & (!is.na(passer_id)) & (!is.na(air_yards)))

p1 <- pbp_pass %>%
  group_by(air_yards) %>%
  summarize(
    completion_pct = mean(complete_pass)
    ) %>%
  ggplot(aes(x = air_yards, y = completion_pct)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(
    title = "All Pass Lengths"
  )

p2 <- pbp_pass %>%
  filter(between(air_yards, 0, 30)) %>%
  group_by(air_yards) %>%
  summarize(
    completion_pct = mean(complete_pass)
    ) %>%
  ggplot(aes(x = air_yards, y = completion_pct)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(
    title = "Passes Between 0 and 30 Yards"
  )

p1 + p2  
```

We'll build a simple logistic regression model for expected completion percentage, just using `air_yards` as the sole predictor.

```{r}
log_reg_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

log_reg_rec <- recipe(complete_pass ~ air_yards, data = pbp_pass) %>%
  step_mutate(complete_pass = as.factor(complete_pass))

log_reg_wf <- workflow() %>%
  add_model(log_reg_spec) %>%
  add_recipe(log_reg_rec)

log_reg_fit <- log_reg_wf %>%
  fit(pbp_pass)

log_reg_fit %>%
  glance()
```

```{r}
log_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

```{r}
log_reg_fit %>%
  augment(pbp_pass) %>%
  mutate(cpoe = complete_pass - .pred_1) %>%
  group_by(season, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    avg_pass_length = mean(air_yards),
    avg_cpoe = mean(cpoe),
    .groups = "drop") %>%
  filter(total_passes > 100) %>%
  arrange(-avg_cpoe) 
```

Let's build a model that can adjust for more complex game scenarios. We'll include `down` (as a factor), yards to go for a first down (`ydstogo`), the `yardline_100`, the `pass_location`, and `qb_hit`. We'll also include an interaction between `down` and `ydstogo`.

```{r}
log_reg_rec <- recipe(complete_pass ~ air_yards + down + ydstogo + yardline_100 + pass_location + qb_hit, data = pbp_pass) %>%
  step_mutate(complete_pass = as.factor(complete_pass)) %>%
  step_mutate(down = as.factor(down)) %>%
  step_mutate(qb_hit = as.factor(qb_hit)) %>%
  step_unknown(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_other(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_interact(~starts_with("down"):ydstogo)

log_reg_wf <- workflow() %>%
  add_model(log_reg_spec) %>%
  add_recipe(log_reg_rec)

log_reg_fit <- log_reg_wf %>%
  fit(pbp_pass)
```

```{r}
log_reg_fit %>%
  glance()
```

```{r}
log_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

Let's re-run our analysis on CPOE, but with this model adjusting for more game scenarios.

```{r}
log_reg_fit %>%
  augment(pbp_pass) %>%
  mutate(cpoe = complete_pass - .pred_1) %>%
  group_by(season, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    avg_pass_length = mean(air_yards),
    avg_cpoe = mean(cpoe),
    completion_pct = mean(complete_pass),
    .groups = "drop") %>%
  filter(total_passes > 100) %>%
  arrange(-avg_cpoe) 
```

Let's investigate the stability of CPOE versus completion percentage.

```{r}
log_reg_fit %>%
  augment(pbp_pass) %>%
  mutate(cpoe = complete_pass - .pred_1) %>%
  group_by(season, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    avg_pass_length = mean(air_yards),
    avg_cpoe = mean(cpoe),
    completion_pct = mean(complete_pass),
    .groups = "drop") %>%
  filter(total_passes > 100) %>%
  group_by(passer_id, passer) %>%
  arrange(season) %>%
  mutate(
    next_total_passes = lead(total_passes),
    next_cpoe = lead(avg_cpoe),
    next_completion_pct = lead(completion_pct)
  ) %>%
  ungroup() %>%
  filter(!is.na(next_total_passes)) %>%
  summarize(
    cor_total_passes = cor(total_passes, next_total_passes),
    cor_completion_pct = cor(completion_pct, next_completion_pct),
    cor_cpoe = cor(avg_cpoe, next_cpoe)
  )
```

Note that the numbers above don't exactly match the numbers suggested by the book. Completion percentage has a correlation of about 0.446 and CPOE has a correlation of about 0.465. Maybe because of how I'm treating novel categories? It also could be that they are using joins and I'm not. The result of my calculation ignores the possibility of a passer getting injured or benched during a season and not meeting my pass requirement threshold. I'll try the join approach from the book below.

```{r}
log_reg_fit %>%
  augment(pbp_pass) %>%
  mutate(cpoe = complete_pass - .pred_1) %>%
  group_by(season, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    avg_pass_length = mean(air_yards),
    avg_cpoe = mean(cpoe),
    completion_pct = mean(complete_pass),
    exp_completion_pct = mean(.pred_1),
    .groups = "drop") %>%
  filter(total_passes > 100) %>%
  group_by(passer_id, passer) %>%
  arrange(season) %>%
  mutate(
    next_season = lead(season),
    next_total_passes = lead(total_passes),
    next_cpoe = lead(avg_cpoe),
    next_completion_pct = lead(completion_pct),
    next_exp_completion_pct = lead(exp_completion_pct)
    ) %>%
  filter(next_season == season + 1) %>%
  ungroup() %>%
  filter(!is.na(next_total_passes)) %>%
  summarize(
    cor_total_passes = cor(total_passes, next_total_passes),
    cor_completion_pct = cor(completion_pct, next_completion_pct),
    cor_cpoe = cor(avg_cpoe, next_cpoe),
    cor_exp_completion_pct = cor(exp_completion_pct, next_exp_completion_pct)
  )
```

That's better. There are some things to note about this analysis, however. Some of the features and feature combinations included in the model could be associated with the Quarterback though. That is, the model may inadvertently account for differences in Quarterback quality, which then confounds our understanding of CPOE. We see that the correlation in expected completion percentage is higher than either completion percentage or CPOE, indicating that Quarterback play is relatively stable year-over-year.

### Discussion on Odds

```{r}
log_reg_fit %>% 
  extract_fit_engine() %>%
  tidy() %>%
  mutate(
    lower_odds = exp(estimate - (2*std.error)),
    odds = exp(estimate),
    upper_odds = exp(estimate + (2*std.error))
    )
```

From the tabular output above, we can see that passes to the middle of the field are about 1.21 times more likely to be completed than passes to the left or right sidelines. Similarly, each additional yard to go decreases the baseline (intercept) odds of completion by a factor of about 0.9443. For example, the baseline (intercept) odds for a pass with a single yard to go is about $2.0506\cdot 0.9443$, or 1.936, which a pass with nine yards to go has completion odds of about $2.0506\times \left(0.9442^9\right)$, or 1.224.

For any singular pass, we can also calculate the expected odds of completion. This can be useful for evaluating real-time game scenarios and play-calling.

```{r}
log_reg_fit %>% 
  augment(pbp_pass) %>%
  mutate(
    odds = .pred_1 / (1 - .pred_1)
  ) %>%
  select(down, ydstogo, yardline_100, air_yards, qb_hit, odds)
```

### Exercises

1. Reproduce this analysis without the `qb_hit` feature. How does it change the leaderboard and what can we take away?
2. What other features could/should be added to our logistic regression? How do these adjustments change the stability estimates.
3. Try the analysis for receivers instead of Quarterbacks -- does anything interesting emerge?
4. Try is again for defensive positions.

## Chapter 6: Poisson Regression and Passing Touchdowns

In this chapter, we focus on *prop* betting and using Poisson regression to model the over/under on number of touchdown passes by a quarterback in a game. The chapter began with an introduction to sports betting -- the three main types being *spread*, *total* (over/under combined point total), and *moneyline*. Prop bets are the least expensive for buy-in and are the most abundant, given the sports-betting apps available today.

Let's start by investigating the distribution of touchdown passes by starting quarterbacks.

```{r}
library(tidyverse)
library(kableExtra)
library(nflfastR)
library(patchwork)
library(tidymodels)
library(poissonreg)

rm(list = ls())

pbp_16_22 <- load_pbp(2016:2022)
pbp_pass <- pbp_16_22 %>%
  filter(play_type == "pass", !is.na(passer_id))

pbp_pass %>%
  group_by(season, week, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    total_tds = sum(touchdown),
    .groups = "drop"
  ) %>%
  filter(total_passes >= 10) %>%
  ggplot(aes(x = total_tds)) + 
  geom_bar(color = "black", fill = "purple") + 
  geom_vline(aes(xintercept = mean(total_tds)), lwd = 1.25, linetype = "dashed")

# pbp_pass %>%
#   group_by(season, week, passer_id, passer) %>%
#   summarize(
#     total_passes = n(),
#     total_tds = sum(touchdown),
#     .groups = "drop"
#   ) %>%
#   filter(total_passes >= 10) %>%
#   summarize(mean(total_tds))
```

This looks like Poisson, with $\lambda = 1.57$ (`mean(total_tds)`). 

```{r}
my_sim_pois <- rpois(5000, lambda = 1.57)
my_sim_pois_freqs <- tibble(my_sim_pois = my_sim_pois) %>%
  count(my_sim_pois) %>%
  mutate(rel_freq = n/sum(n))

p1 <- pbp_pass %>%
  group_by(season, week, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    total_tds = sum(pass_touchdown),
    avg_line = mean(total_line),
    .groups = "drop"
  ) %>%
  filter(total_passes > 10) %>%
  ggplot(aes(x = total_tds)) + 
  geom_bar(aes(y = after_stat(prop)), color = "black", fill = "purple") + 
  geom_line(data = my_sim_pois_freqs,
            aes(x = my_sim_pois, y = rel_freq),
            lwd = 1.25,
            linetype = "dashed")

p2 <- ggplot() + 
  geom_bar(aes(x = my_sim_pois, y = after_stat(prop)),
                 color = "black", fill = "darkgreen")

p1 / p2
```

They look pretty similar to me! I'll save out our weekly touchdown counts by quarterback since we'll use it throughout the remainder here.

```{r}
weekly_td_count <- pbp_pass %>%
  group_by(season, week, passer_id, passer) %>%
  summarize(
    total_passes = n(),
    total_pass_tds = sum(pass_touchdown),
    avg_line = mean(total_line),
    .groups = "drop"
  ) %>%
  filter(total_passes > 10)
```

We're going to build a model that includes the average prior per-game touchdowns up to that season and week. Notice that the textbook limits the calculations to include only the previous season and completed games from the current season. This seems appropriate, and I think I would need a loop for this purpose. I suppose I could always use a join instead to join the previous season average, per-game passing touchdowns as a new column. It's not important for now, and I'll return to this later.

```{r}
season_td_avgs <- weekly_td_count %>%
  group_by(passer_id, passer, season) %>%
  summarize(
    avg_tds = mean(total_pass_tds),
    .groups = "drop"
  ) %>%
  group_by(passer_id, passer) %>%
  mutate(
    last_season_avg_tds = lag(avg_tds, default = 0)
  )

weekly_td_count %>%
  left_join(
    season_td_avgs %>% select(-avg_tds)
  ) %>%
  group_by(passer_id, passer) %>%
  arrange(season, week) %>%
  mutate(
    total_games = row_number(),
    cum_total_pass_tds = cumsum(total_pass_tds),
    cum_avg_pass_tds = (18*last_season_avg_tds + week*cummean(total_pass_tds))/(18 + week)
  )
```

Let's plot the results.

```{r}
weekly_td_count %>%
  left_join(
    season_td_avgs %>% select(-avg_tds)
  ) %>%
  group_by(passer_id, passer) %>%
  arrange(season, week) %>%
  mutate(
    total_games = row_number(),
    cum_total_pass_tds = cumsum(total_pass_tds),
    cum_avg_pass_tds = (18*last_season_avg_tds + week*cummean(total_pass_tds))/(18 + week)
  ) %>%
  ggplot(aes(x = week, y = cum_avg_pass_tds, color = passer_id)) +
  geom_line(alpha = 0.2) +
  facet_wrap(~season) + 
  theme_bw() +
  theme(legend.position = "none")
```

We can add a Poisson regression line as follows.

```{r}
#| warning: false
#| message: false

weekly_td_count %>%
  left_join(
    season_td_avgs %>% select(-avg_tds)
  ) %>%
  group_by(passer_id, passer) %>%
  arrange(season, week) %>%
  mutate(
    total_games = row_number(),
    cum_total_pass_tds = cumsum(total_pass_tds),
    cum_avg_pass_tds = (18*last_season_avg_tds + week*cummean(total_pass_tds))/(18 + week)
  ) %>%
  ggplot(aes(x = week, y = cum_avg_pass_tds)) +
  geom_line(aes(color = passer_id), alpha = 0.2) +
  geom_smooth(method = "glm", method.args = list("family" = "poisson")) + 
  facet_wrap(~season) + 
  theme_bw() +
  theme(legend.position = "none")
```

Let's fit a Poisson Regression model.

```{r}
weekly_td_for_model <- weekly_td_count %>%
  left_join(
    season_td_avgs %>% select(-avg_tds)
  ) %>%
  group_by(passer_id, passer) %>%
  arrange(season, week) %>%
  mutate(
    total_games = row_number(),
    cum_total_pass_tds = cumsum(total_pass_tds),
    cum_avg_pass_tds = (18*last_season_avg_tds + week*cummean(total_pass_tds))/(18 + week),
    incoming_avg_pass_tds = lag(cum_avg_pass_tds)
  ) %>%
  ungroup()

pois_reg_spec <- poisson_reg() %>%
  set_engine("glm") %>%
  set_mode("regression")

pois_reg_rec <- recipe(total_pass_tds ~ cum_avg_pass_tds + avg_line, data = weekly_td_for_model)

pois_reg_wf <- workflow() %>%
  add_model(pois_reg_spec) %>%
  add_recipe(pois_reg_rec)

pois_reg_fit <- pois_reg_wf %>%
  fit(weekly_td_for_model)

pois_reg_fit %>%
  extract_fit_parsnip() %>%
  tidy()
```

### Replicating the Book

```{r}
pbp <- load_pbp(2016:2022)
pbp_pass <- pbp %>%
  filter(!is.na(passer_id))

pbp_pass_td <- pbp_pass %>%
  mutate(
    pass_touchdown = ifelse(is.na(pass_touchdown), 0, pass_touchdown)
  ) %>%
  group_by(season, week, passer_id, passer) %>%
  summarize(
    n_passes = n(),
    total_pass_td = sum(pass_touchdown),
    total_line = mean(total_line),
    .groups = "drop"
  ) %>%
  filter(n_passes >= 10)

pbp_pass_td %>%
  count(total_pass_td)

results_df <- tibble()

for(season_idx in 2017:2022){
  for(week_idx in 1:22){
    week_calc <- pbp_pass_td %>%
      filter((season == (season_idx - 1)) | ((season == season_idx) & (week < week_idx))) %>%
      group_by(passer_id, passer) %>%
      summarize(
        n_games = n(),
        avg_pass_td = mean(total_pass_td),
        .groups = "keep") %>%
      mutate(
        season = season_idx,
        week = week_idx
      )
    results_df <- bind_rows(results_df, week_calc)
  }
}

results_df %>%
  filter(passer == "P.Mahomes") %>%
  tail()

pbp_pass_td_model <- pbp_pass_td %>%
  inner_join(
    results_df
  )
```

```{r}
pois_reg_spec <- poisson_reg() %>%
  set_engine("glm") %>%
  set_mode("regression")

pois_reg_rec <- recipe(total_pass_td ~ avg_pass_td + total_line, data = pbp_pass_td_model)

pois_reg_wf <- workflow() %>%
  add_model(pois_reg_spec) %>%
  add_recipe(pois_reg_rec)

pois_reg_fit <- pois_reg_wf %>%
  fit(pbp_pass_td_model)

pois_reg_fit %>%
  extract_fit_parsnip() %>%
  tidy()
```

Now that I've got the same mode from the text, I'll move forward with interpretations of the model coefficients. Note that the Poisson regression model coefficients are on an exponential scale.

```{r}
pois_reg_fit %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  mutate(
    exp_lower = exp(estimate - 2*std.error),
    exp_estimate = exp(estimate),
    exp_upper = exp(estimate + 2*std.error)
  )
```

+ For each touchdown in the player's historical per-game average, we can multiply by about 1.36 to get the expected number of touchdown passes
+ The `total_line` is quite efficient (only being off by about 2%), we multiply the line by about 1.02.

We can use the model to make a prediction for Patrick Mahomes' superbowl LVIII against the Eagles.

```{r}
pois_reg_fit %>% augment(
  pbp_pass_td_model %>%
    filter(season == 2022, week == 22, passer == "P.Mahomes")
)

```

The output above shows that, Mahomes' average passing touchdown count over the previous 39 games (the 2021 season and all prior games in 2022) was 2.38 and that our model expects that he'll throw for about 2.11 touchdowns in the Superbowl. Note that part of this expectation is *regression toward the mean* -- Mahomes, the best quarterback in the league, is pulled down towards the average by the model.

The betting market in this scenario already favored below the 2.5 touchdown line. We want to know whether the market has made this "too much" or "too little" a favorite by their implied odds.

```{r}
pois_reg_fit %>% 
  augment(pbp_pass_td_model) %>%
  mutate(
    p_0_td = dpois(0, .pred),
    p_1_td = dpois(1, .pred),
    p_2_td = dpois(2, .pred),
    p_under = ppois(2, .pred),
    p_over = 1 - p_under
  ) %>%
  filter(season == 2022, week == 22, passer == "P.Mahomes")
```

Recall that we needed at least a 40% chance of Mahomes exceeding the line in order to expect to at least break even on betting the over.

```{r}
100/(100 + 150)
```

Our predicted probability is too low to justify that bet. Additionally, the 64.7% is also slightly shy of the 64.9% that we needed to justify betting on the under.

```{r}
185/(100 + 185)
```

:::{.callout-tip}
The textbook suggests that, in all but a few cases, we should not bet. The sportsbooks set their lines so that we are near the break-even point, but their "vigorish" (the money they skim of the top in order to profit) generally pushes the expectations below the threshold to make a bet.
:::

:::{.callout-note}
## Moneyline to Percentages
If the moneyline is negative, take the absolute value of the moneyline and divide it 100 more than the absolute value of the moneyline. If the moneyline is positive, take the quotient of the moneyline to 100 more than the money line. That is,

$$\frac{\left|\text{moneyline}\right|}{\left|\text{moneyline}\right| + 100}~~~~~\text{ or }~~~~~\frac{\text{moneyline}}{\text{moneyline} + 100}$$

To get the percentage corresponding to an *under*, subtract the above quotient from 1.
:::

:::{.callout-important}
## Poisson Regression Coefficients
The exponentiated regression coefficients from a Poisson regression model are multiplicative, like those exponentiated coefficients (odds) in a logistic regression model. Take care with your interpretations.
:::

### Modeling TDs per Game for Baltimore 

In 2022, the Ravens lost their starting quarterback in Week 13. We may wonder if the expected number of touchdowns per game drops as a result of injuries to players throughout the season.

```{r}
bal_td <- pbp %>%
  filter(posteam == "BAL", season == 2022) %>%
  group_by(game_id, week) %>%
  summarize(
    td_per_game = sum(touchdown, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    week = week - 1 #to shift Week 1 to intercept
  )

bal_td %>%
  ggplot(aes(x = week, y = td_per_game)) + 
  geom_point() + 
  geom_smooth(method = "glm", method.args = list("family" = "poisson"))
```

Let's fit the model and analyze the coefficients.

```{r}
pois_reg_spec <- poisson_reg() %>%
  set_engine("glm") %>%
  set_mode("regression")

pois_reg_rec <- recipe(td_per_game ~ week, data = bal_td)

pois_reg_wf <- workflow() %>%
  add_model(pois_reg_spec) %>%
  add_recipe(pois_reg_rec)

pois_reg_fit <- pois_reg_wf %>%
  fit(bal_td)

pois_reg_fit %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  mutate(
    exp_lower = exp(estimate - 2*std.error),
    exp_est = exp(estimate),
    exp_upper = exp(estimate + 2*std.error)
  )
```

The raw slope coefficient is the *risk ratio* or *relative risk* for each week. That coefficient being negative indicates that the expected number of touchdowns decreases as weeks go by. After exponentiating, we get an intercept of 3.502 and a slope coefficient of 0.939. The intercept is the expected number of touchdowns in Week 1 (remember we subtracted 1 from the week) and then the 0.939 is a deflation factor from week to week. For example, in week 5 we should expect $3.502\times\left(0.939^4\right) \approx 2.72$ touchdowns for the Ravens.

### Exercises

1. What happens in the model for touchdown passes if you don't include the total for the game? Does it change any of the probabilities enough to recommend a bet for Mahomes' superbowl passing touchdown total?
2. Repeat the work in the chapter for interceptions thrown.
3. Repeat the touchdown and interception analysis for Jalen Hurts. Do the results permit a bet on (or against) Hurts?
4. Improve your model -- perhaps including weather features.
5. Try using a quasi-Poisson model to estimate dispersion parameters.
6. Use a negative binomial model instead of a Poisson model for the analyses completed in this chapter.

## Chapter 7: Web-Scraping, Obtaining and Analyzing Draft Picks

```{r}
rm(list = ls())

library(tidyverse)
library(tidymodels)
library(rvest)
library(janitor)
library(zoo)
library(htmlTable)
```

We'll try extracting data from the NFL Draft and from the NFL Combine. The code cell below is set not to run because we ran it once to scrape the data and then saved out the results to a local csv file. This prevents us from pinging the site too often and getting rate-limited or blocked. When we want updated data, we simply edit the code below, run it, save out the results, and then reset `eval` to false.

```{r}
#| warning: false
#| message: false
#| eval: false

draft_df <- tibble()

for(year_idx in 2000:2022){
  url <- paste0("https://www.pro-football-reference.com/years/", year_idx, "/draft.htm")
  
  web_data <- read_html(url) %>%
    html_nodes(xpath = '//*[@id="drafts"]') %>%
    html_table()
  
  web_df <- web_data[[1]]
  
  web_df_clean <- web_df %>%
    janitor::row_to_names(row_number = 1) %>%
    janitor::clean_names(case = "none") %>%
    mutate(season = year_idx) %>%
    filter(Tm != "Tm")
  
  draft_df <- draft_df %>%
    bind_rows(web_df_clean)
}
```

Now we'll rename the teams that have moved cities during this time period.

```{r}
#| eval: false

draft_df <- draft_df %>%
  mutate(
    Tm = case_when(
      Tm == "SDG" ~ "LAC",
      Tm == "OAK" ~ "LRV",
      Tm == "STL" ~ "LAR",
      TRUE ~ Tm
    )
  )

write.csv(draft_df, "draft_00_22.csv", row.names = FALSE)
```

```{r}
draft_df <- read_csv("draft_00_22.csv")

draft_used <- draft_df %>%
  select(season, Pick, Tm, Player, Pos, wAV, DrAV)

draft_used
```

Notice that players making the *Hall of Fame* are labeled with the suffix `HOF` -- we'll remove that in case we want to join this data frame with another one using player names as a key.

```{r}
draft_used <- draft_used %>%
  mutate(Player = str_remove(Player, " HOF$"))

draft_used
```

We're going to attempt to recreate an analysis done to show that the surplus-value (on-field value adjusted for salary) is maximized my mid-to-late first-rounders and early second-round draft picks. The value decays exponentially with pick number. We'll use the *draft approximate value* (`DrAV`). We'll also filter out players drafted in 2020 and beyond because they're still playing under their rookie contracts.

```{r}
draft_used %>%
  mutate(
    DrAV = as.numeric(DrAV),
    wAV = as.numeric(wAV),
    Pick = as.integer(Pick)
  ) %>%
  filter(season <= 2019) %>%
  # group_by(Pick) %>%
  # summarize(avg_DrAV = mean(DrAV),
  #           .groups = "drop") %>%
  ggplot(aes(x = Pick, y = DrAV)) +
  geom_smooth() + 
  geom_point(alpha = 0.05) + 
  theme_bw()
  
```

We can see the line of decay there. The real question now is what teams are looking for when they draft. The average value for late picks is likely to be skewed higher by "hits" on those picks, but the median for those late picks is likely to be very close to 0. Those late picks certainly don't carry 0 value though because teams trade those picks (and the players drafted with them) quite often. 

For now, we'll use the mean, but *quantile regression* is discussed later in the book (page 242). We'll use a rolling mean with a centered window and six picks on either side.

```{r}
draft_rolling_mean <- draft_df %>%
  mutate(
    DrAV = as.numeric(DrAV),
    wAV = as.numeric(wAV),
    Pick = as.integer(Pick)
  ) %>%
  filter(season <= 2019) %>%
  group_by(Pick) %>%
  summarize(mean_DrAV = mean(DrAV, na.rm = TRUE)) %>%
  mutate(mean_DrAV = ifelse(is.na(mean_DrAV), 0, mean_DrAV)) %>%
  mutate(
    roll_DrAV = rollapply(mean_DrAV,
                          width = 13,
                          FUN = mean,
                          na.rm = TRUE,
                          fill = "extend",
                          partial = TRUE
                          )
  )

draft_rolling_mean %>%
  ggplot(aes(x = Pick, y = roll_DrAV)) +
  geom_point() + 
  geom_smooth() + 
  labs(
    x = "Pick Number",
    y = "Rolling average (\u00B1 6) DrAV"
  ) +
  theme_bw()
```

Let's fit a model and then analyse the results.

```{r}
lin_reg_spec <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

lin_reg_rec <- recipe(roll_DrAV ~ Pick, data = draft_rolling_mean) %>%
  step_mutate(roll_DrAV = log(roll_DrAV + 1))

lin_reg_wf <- workflow() %>%
  add_model(lin_reg_spec) %>%
  add_recipe(lin_reg_rec)

lin_reg_fit <- lin_reg_wf %>%
  fit(draft_rolling_mean)

lin_reg_fit %>%
  extract_fit_parsnip() %>%
  tidy()
```

Now we'll augment our data with the draft predictions.

```{r}
draft_rolling_mean_preds <- lin_reg_fit %>%
  augment(draft_rolling_mean) %>%
  mutate(.pred = ifelse(.pred < 0, 0, .pred)) %>%
  mutate(fitted_DrAV = exp(.pred) - 1)

draft_rolling_mean_preds
```

While this model fit is quite poor (it drastically underestimates the value of early picks), we can still use it to explore draft situations. We'll try evaluating the Jets/Colts 2018 trade.

```{r}
future_pick <- tibble(
  Pick = "Future 2nd round",
  Value = "14.8 (discounted at rate of 25%)"
)

team <- tibble(
  ReceivingTeam = c("Jets", rep("Colts", 4))
)

tbl_1 <- draft_rolling_mean_preds %>%
  filter(Pick %in% c(3, 6, 37, 49)) %>%
  select(Pick, fitted_DrAV) %>%
  rename(Value = fitted_DrAV) %>%
  mutate(
    Pick = as.character(Pick),
    Value = as.character(round(Value, 1))
  ) %>%
  bind_rows(
    future_pick
  )

team %>%
  bind_cols(tbl_1)
```

The Jets made a terrible trade here. They got an expected 29.4 DrAV, but then gave away 86.5 in DrAV -- that nets the trade at -57.1 DrAV for the Jets. The actual results for the Jets were even worse, after accounting for the actual value of the players the Colts got with their picks.

We may also wonder whether some teams are better at drafting than others. This is tricky to answer though because team performance in the field is associated with their drafting order. Since the best players are picked early in the draft, we don't want to just erroneously claim that the worst teams are the best drafters. 

```{r}
lin_reg_fit %>%
  augment(draft_used %>% 
            filter(season <= 2019) %>%
            mutate(roll_DrAV = 1),
          type = "response") %>%
  group_by(Tm) %>%
  summarize(
    total_picks = n(),
    DrAV_OE = mean(DrAV - .pred, na.rm = TRUE),
    DrAV_sigma = sd(DrAV - .pred, na.rm = TRUE),
    se = DrAV_sigma/sqrt(total_picks),
    lower_bound = DrAV_OE - 2*se,
    upper_bound = DrAV_OE + 2*se
  ) %>%
  arrange(-DrAV_OE)
```

Again, I'm not replicating the values from the text here. My model was slightly different than the one in the book, which could be contributing here.

### Exercises

1. Change the web-scraping examples to different ranges of years. Identify whether errors arise, and why.
2. Scrap NFL scouting combine data from Pro Football Reference, updating the URL to `.../draft/YEAR-combine.htm`
3. Plot the 40-yard dash times using the combine data, coloring each point by player position. Which positions are fastest/slowest, and what other patterns do you notice?
4. Join the draft and combine data together -- is there an association between 40-yard dash time and draft position? Is that relationship more pronounced for some positions?
5. Revisit the draft curve, constructing it for a rolling median instead of rolling mean.


